{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import synthetic_data\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as Fun\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "##### train and test data:\n",
    "\n",
    "context_generator = synthetic_data.QuinticContexts(  )\n",
    "context_generator.set_b(0)\n",
    "context_generator.normalization()\n",
    "\n",
    "\n",
    "X_train, y_train, dist_train = None, None, []\n",
    "X_test, y_test, dist_test = None, None, []\n",
    "\n",
    "for _ in range(10000):\n",
    "    norm_context, distribution = context_generator.get_context(True)\n",
    "    dist_train.append(distribution)\n",
    "    outcome = np.random.choice( 2 , p = distribution ) \n",
    "    X_train = norm_context if X_train is None else np.concatenate((X_train, norm_context), axis=0)\n",
    "    y_train = [[outcome]] if y_train is None else np.concatenate( (y_train, [[outcome]]), axis=0)\n",
    "\n",
    "for _ in range(10000):\n",
    "    norm_context, distribution = context_generator.get_context(True)\n",
    "    dist_test.append(distribution)\n",
    "    outcome = np.random.choice( 2 , p = distribution ) \n",
    "    X_test = norm_context if X_test is None else np.concatenate((X_test, norm_context), axis=0)\n",
    "    y_test = [[outcome]] if y_test is None else np.concatenate( (y_test, [[outcome]]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OriginalNetwork(nn.Module):\n",
    "    def __init__(self,  d, m):\n",
    "        super(OriginalNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(d, m)\n",
    "        self.activate1 = nn.Tanh() #nn.ReLU()\n",
    "        self.fc2 = nn.Linear(m, m)\n",
    "        self.activate2 = nn.Tanh() #nn.ReLU()\n",
    "        self.fc3 = nn.Linear(m, m)\n",
    "        self.activate3 = nn.Tanh() #nn.ReLU()\n",
    "        self.fc4 = nn.Linear(m, 1)\n",
    "        nn.init.normal_(self.fc1.weight, mean=0, std=0.1)\n",
    "        nn.init.normal_(self.fc2.weight, mean=0, std=0.1)\n",
    "        nn.init.normal_(self.fc3.weight, mean=0, std=0.1)\n",
    "        nn.init.normal_(self.fc4.weight, mean=0, std=0.1)\n",
    "        nn.init.zeros_(self.fc1.bias)\n",
    "        nn.init.zeros_(self.fc2.bias)\n",
    "        nn.init.zeros_(self.fc3.bias)\n",
    "        nn.init.zeros_(self.fc4.bias)\n",
    "    def forward(self, x):\n",
    "        x = self.fc4( self.activate3( self.fc3( self.activate2( self.fc2( self.activate1( self.fc1( x ) ) ) ) ) ) )\n",
    "        # x = self.fc2( self.activate1( self.fc1(x) ) ) \n",
    "        return x\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "torch.manual_seed(41)\n",
    "\n",
    "# Create the model instance\n",
    "model = OriginalNetwork(2, 20).to('cuda')\n",
    "\n",
    "# Define the loss function (mean squared error) and optimizer\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-1, weight_decay = 0 )\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.99)\n",
    "\n",
    "for _ in range(1000):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    outputs = model( torch.tensor(X_train).to('cuda').float() ) \n",
    "    loss = nn.MSELoss()(outputs, torch.tensor(y_train).to('cuda').float() )\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    ### test and deployment loss:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs_test = model( torch.tensor(X_test).to('cuda').float() ).to('cpu').float() \n",
    "        loss_test = nn.MSELoss()(outputs_test, torch.tensor(y_test).to('cpu').float() )\n",
    "\n",
    "        outputs_depl = model( torch.tensor(X_depl).to('cuda').float() ).to('cpu').float() \n",
    "        loss_depl = nn.MSELoss()(outputs_depl, torch.tensor(y_depl).to('cpu').float() )\n",
    "\n",
    "    if _ % 10 == 0 :\n",
    "        scheduler.step()\n",
    "        print(f'Epoch {_}, Train loss: {loss.item():.4f}, Test loss: {loss_test.item():.4f}, Depl loss: {loss_depl.item():.4f}')\n",
    "\n",
    "# torch.save(model.state_dict(), './models/quintic.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of x and y values for the grid\n",
    "x_min, x_max = -1, 1\n",
    "y_min, y_max = -1, 1\n",
    "\n",
    "# Generate a grid of points\n",
    "num_points = 1000\n",
    "x_values = np.linspace(x_min, x_max, num_points)  \n",
    "y_values = np.linspace(y_min, y_max, num_points)  \n",
    "x_grid, y_grid = np.meshgrid(x_values, y_values)\n",
    "\n",
    "# Compute the decision boundary for the grid of points\n",
    "for idx, data in enumerate( [ (X_test,outputs_test), (X_depl, outputs_depl) ] ):\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "\n",
    "    b = 0 if idx == 0 else 0.15\n",
    "    decision_boundary_grid = context_generator.decision_boundary_function(x_grid, y_grid, b)\n",
    "\n",
    "    plt.contourf(x_grid, y_grid, decision_boundary_grid, levels=1, alpha=0.6, cmap=plt.cm.coolwarm)\n",
    "\n",
    "    contexts = np.array( [ context_generator.denormalize(i) for i in data[0] ] ).squeeze(1)\n",
    "\n",
    "    pred_action0 = [ i[0] if i[0] > 0.5 else np.nan for i in data[1]  ]\n",
    "    indices_predaction0 = np.where(~np.isnan(pred_action0))[0]\n",
    "    pred_action1 = [ i[0] if i[0] <= 0.5 else np.nan for i in data[1]  ]\n",
    "    indices_predaction1 = np.where(~np.isnan(pred_action1))[0]\n",
    "\n",
    "    plt.scatter(contexts[indices_predaction0][:,0], contexts[indices_predaction0][:,1], s = 1, color='blue', label='Predicted Points')\n",
    "    plt.scatter(contexts[indices_predaction1][:,0], contexts[indices_predaction1][:,1], s = 1, color='red', label='Predicted Points')\n",
    "\n",
    "    # Add labels and title to the plot\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    # plt.title(' Decision Boundary')\n",
    "    # Adjust the layout for better spacing\n",
    "    plt.tight_layout()\n",
    "    plt.ylim((-1,1))\n",
    "    plt.xlim((-1,1))\n",
    "\n",
    "    # Save the figure to a file with tight layout and 380 DPI\n",
    "    plt.savefig('./figures/decision_boundary_{}.png'.format(idx), dpi=380, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
