{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import pickle as pkl\n",
    "\n",
    "def loadall_results2(path, n_folds):\n",
    "    regret = []\n",
    "    history_actions = []\n",
    "    history_outcomes = []\n",
    "    perf = []\n",
    "    with gzip.open(  path ,'rb') as f:\n",
    "        for i in range(n_folds+1):\n",
    "            try:\n",
    "                data = pkl.load(f)\n",
    "            except EOFError:\n",
    "                break\n",
    "\n",
    "            if type(data) == dict:\n",
    "                regret.append( data['regret'] ) \n",
    "                history_actions.append( data['action_history'] )\n",
    "                history_outcomes.append( data['outcome_history'] ) \n",
    "                perf.append( data['pred'] ) \n",
    "\n",
    "    return regret, history_actions, history_outcomes, perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 25\n",
    "horizon = 9999\n",
    "context = 'MNISTbinary'\n",
    "model = 'MLP'\n",
    "case = 'case1'\n",
    "agent_name = 'EEneuralcbpside_v6' #ineural6, neuronal6\n",
    "\n",
    "direct = './results/'\n",
    "path = os.path.join(direct, '{}_{}_{}_{}_{}_{}.pkl.gz'.format(case,model,context,horizon,n_folds,agent_name) )\n",
    "regret, action_history,outcome_history, perf = loadall_results2(path, n_folds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the list to create a format suitable for DataFrame\n",
    "\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(processed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./results/case1_MLP_MNISTbinary_9999_25_EEneuralcbpside_v6.pkl.gz\n",
      "./results/case1_MLP_MNISTbinary_9999_25_ineural6.pkl.gz\n",
      "./results/case1_MLP_MNISTbinary_9999_25_ineural3.pkl.gz\n",
      "./results/case1_MLP_MNISTbinary_9999_25_neuronal6.pkl.gz\n",
      "./results/case1_MLP_MNISTbinary_9999_25_neuronal3.pkl.gz\n",
      "./results/case1_MLP_MNISTbinary_9999_25_margin.pkl.gz\n",
      "./results/case1_MLP_MNISTbinary_9999_25_cesa.pkl.gz\n",
      "./results/case1_MLP_MagicTelescope_9999_25_EEneuralcbpside_v6.pkl.gz\n",
      "./results/case1_MLP_MagicTelescope_9999_25_ineural6.pkl.gz\n",
      "./results/case1_MLP_MagicTelescope_9999_25_ineural3.pkl.gz\n",
      "./results/case1_MLP_MagicTelescope_9999_25_neuronal6.pkl.gz\n",
      "./results/case1_MLP_MagicTelescope_9999_25_neuronal3.pkl.gz\n",
      "./results/case1_MLP_MagicTelescope_9999_25_margin.pkl.gz\n",
      "./results/case1_MLP_MagicTelescope_9999_25_cesa.pkl.gz\n",
      "./results/case1_MLP_adult_9999_25_EEneuralcbpside_v6.pkl.gz\n",
      "./results/case1_MLP_adult_9999_25_ineural6.pkl.gz\n",
      "./results/case1_MLP_adult_9999_25_ineural3.pkl.gz\n",
      "./results/case1_MLP_adult_9999_25_neuronal6.pkl.gz\n",
      "./results/case1_MLP_adult_9999_25_neuronal3.pkl.gz\n",
      "./results/case1_MLP_adult_9999_25_margin.pkl.gz\n",
      "./results/case1_MLP_adult_9999_25_cesa.pkl.gz\n"
     ]
    }
   ],
   "source": [
    "def format_perf(perf, model, dataset, l_label):\n",
    "\n",
    "    processed_data = []\n",
    "    i = 0\n",
    "    for item in perf:\n",
    "        processed_item = {}\n",
    "        key_mapping = dict( zip( item.keys(), [10, 50, 100, 250, 500, 750, 1000, 2500, 5000, 7500, 9000]))\n",
    "        new_dict = {key_mapping[old_key]: value for old_key, value in item.items()}\n",
    "        for key in new_dict:\n",
    "            # processed_item[f'accuracy_{key}'] = new_dict[key]['accuracy']\n",
    "            processed_item[f'f1_{key}'] = new_dict[key]['f1']\n",
    "        processed_item['Seed'] = i\n",
    "        processed_item['Model'] = model\n",
    "        processed_item['Dataset'] = dataset\n",
    "        processed_item['Approach'] = l_label\n",
    "        i = i+1\n",
    "        processed_data.append(processed_item)\n",
    "    return processed_data\n",
    "\n",
    "\n",
    "\n",
    "n_folds = 26\n",
    "horizon = 9999\n",
    "model = 'MLP'\n",
    "\n",
    "material = {\n",
    "    #'EEneuralcbpside_v5': {'color': [255, 255, 0], 'label': 'EEneuralcbpside_v5'},  # Red\n",
    "    'EEneuralcbpside_v6': {'color': [255, 0, 0], 'label': 'Neural-CBP'},  # Red\n",
    "    'ineural6': {'color': [51, 255, 255], 'label':'IneurAL (official)'},                    # Yellow\n",
    "    'ineural3': {'color': [0, 0, 255], 'label':'IneurAL (tuned)'},                    # Cyan\n",
    "    'neuronal6': {'color': [255, 0, 255], 'label':'Neuronal (official)'},                  # Magenta\n",
    "    'neuronal3': {'color': [160, 160, 160], 'label':'Neuronal (tuned)'},                   # Orange\n",
    "    'margin': {'color': [160, 160, 160], 'label':'Margin'},\n",
    "    'cesa': {'color': [0, 0, 255], 'label':'Cesa'},\n",
    "}\n",
    "\n",
    "fig = go.Figure( )\n",
    "\n",
    "data_models = {}\n",
    "perfs_final = {}\n",
    "for model in ['MLP']:  # 'LeNet'\n",
    "\n",
    "    if model == 'MLP':\n",
    "        n_folds = 25\n",
    "        datasets = ['MNISTbinary', 'MagicTelescope', 'adult', ] # 'MNIST', 'FASHION', 'covertype', 'shuttle',\n",
    "    # else:\n",
    "    #     datasets = ['MNIST', 'FASHION', 'CIFAR10',]\n",
    "    #     n_folds = 25\n",
    "\n",
    "    data_regrets = {} \n",
    "    data_perfs = {} \n",
    "    for data in datasets: \n",
    "\n",
    "        # if data in ['MNIST', 'FASHION', 'CIFAR10']:\n",
    "        #     case = 'case2' \n",
    "        # elif data in ['covertype', 'shuttle']:\n",
    "        #     case = 'game_case_seven'\n",
    "        # else:\n",
    "        case = 'case1'\n",
    "        \n",
    "        final_regrets = {}\n",
    "        final_perfs = {}\n",
    "        for agent_name in material.keys():\n",
    "\n",
    "            color, l_label = material[agent_name]['color'], material[agent_name]['label']\n",
    "\n",
    "            r,g,b = color\n",
    "\n",
    "            # try:\n",
    "            direct = './results/'\n",
    "            path = os.path.join(direct, '{}_{}_{}_{}_{}_{}.pkl.gz'.format(case, model, data, horizon,n_folds,agent_name) )\n",
    "            print(path)\n",
    "            regret, action_history,outcome_history, perf = loadall_results2(path, n_folds)\n",
    "            regret = np.array(regret)\n",
    "            regret = regret#[1:]\n",
    "            # regret = regret.astype(np.float32)\n",
    "            # print(regret.shape)\n",
    "            \n",
    "            final_regrets[l_label] = regret[:,-1] \n",
    "            final_perfs[l_label] = pd.DataFrame( format_perf(perf, model, data, l_label) )\n",
    "            # except:\n",
    "            #     print('hey')\n",
    "            #     regret = np.zeros((n_folds,horizon))\n",
    "\n",
    "        if data == 'MNISTbinary':\n",
    "            data = 'MNISTbinary'\n",
    "        if data == 'FASHION':\n",
    "            data = 'Fashion'\n",
    "            \n",
    "        data_regrets[data] = final_regrets\n",
    "\n",
    "        dataframes_list = list(final_perfs.values())\n",
    "        concatenated_df = pd.concat(dataframes_list, axis=0)\n",
    "        data_perfs[data] = concatenated_df\n",
    "        \n",
    "    data_models[model] = data_regrets\n",
    "    dataframes_list = list(data_perfs.values())\n",
    "    concatenated_df = pd.concat(dataframes_list, axis=0)\n",
    "\n",
    "# fig.show()\n",
    "# fig.write_image(\"./figures/case1_{}_{}.pdf\".format(model, context) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: {'accuracy': 0.7618397707110687, 'f1': 0.658856549710928, 'nverifs': 2},\n",
       " 50: {'accuracy': 0.7618397707110687, 'f1': 0.658856549710928, 'nverifs': 7},\n",
       " 100: {'accuracy': 0.7618397707110687, 'f1': 0.658856549710928, 'nverifs': 13},\n",
       " 250: {'accuracy': 0.7618397707110687, 'f1': 0.658856549710928, 'nverifs': 18},\n",
       " 500: {'accuracy': 0.7618397707110687, 'f1': 0.658856549710928, 'nverifs': 27},\n",
       " 750: {'accuracy': 0.7618397707110687, 'f1': 0.658856549710928, 'nverifs': 37},\n",
       " 1000: {'accuracy': 0.7618397707110687,\n",
       "  'f1': 0.658856549710928,\n",
       "  'nverifs': 44},\n",
       " 2500: {'accuracy': 0.7618397707110687,\n",
       "  'f1': 0.658856549710928,\n",
       "  'nverifs': 76},\n",
       " 5000: {'accuracy': 0.7618397707110687,\n",
       "  'f1': 0.658856549710928,\n",
       "  'nverifs': 124},\n",
       " 7500: {'accuracy': 0.7618397707110687,\n",
       "  'f1': 0.658856549710928,\n",
       "  'nverifs': 158},\n",
       " 9000: {'accuracy': 0.7618397707110687,\n",
       "  'f1': 0.658856549710928,\n",
       "  'nverifs': 177}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a mapping from old keys to new keys\n",
    "\n",
    "\n",
    "new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_1</th>\n",
       "      <th>f1_1</th>\n",
       "      <th>accuracy_51</th>\n",
       "      <th>f1_51</th>\n",
       "      <th>accuracy_88</th>\n",
       "      <th>f1_88</th>\n",
       "      <th>accuracy_137</th>\n",
       "      <th>f1_137</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Model</th>\n",
       "      <th>...</th>\n",
       "      <th>accuracy_94</th>\n",
       "      <th>f1_94</th>\n",
       "      <th>accuracy_50</th>\n",
       "      <th>f1_50</th>\n",
       "      <th>accuracy_96</th>\n",
       "      <th>f1_96</th>\n",
       "      <th>accuracy_227</th>\n",
       "      <th>f1_227</th>\n",
       "      <th>accuracy_281</th>\n",
       "      <th>f1_281</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.767436</td>\n",
       "      <td>0.666454</td>\n",
       "      <td>0.781766</td>\n",
       "      <td>0.703452</td>\n",
       "      <td>0.795278</td>\n",
       "      <td>0.734284</td>\n",
       "      <td>0.797598</td>\n",
       "      <td>0.740024</td>\n",
       "      <td>0</td>\n",
       "      <td>MLP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.760338</td>\n",
       "      <td>0.656822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>MLP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.765934</td>\n",
       "      <td>0.664413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>MLP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>MLP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.755425</td>\n",
       "      <td>0.650175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>MLP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.786952</td>\n",
       "      <td>0.733573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>MLP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.755835</td>\n",
       "      <td>0.650729</td>\n",
       "      <td>0.785997</td>\n",
       "      <td>0.751336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>MLP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.760202</td>\n",
       "      <td>0.656637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>MLP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>MLP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.756790</td>\n",
       "      <td>0.652020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>MLP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>MLP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.755425</td>\n",
       "      <td>0.650175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>MLP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>MLP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.757063</td>\n",
       "      <td>0.652389</td>\n",
       "      <td>0.791320</td>\n",
       "      <td>0.737025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>MLP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.763068</td>\n",
       "      <td>0.660522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>MLP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.758018</td>\n",
       "      <td>0.653681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>MLP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>MLP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.753105</td>\n",
       "      <td>0.647043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>MLP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>MLP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>MLP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>MLP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.757745</td>\n",
       "      <td>0.653312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>MLP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.759383</td>\n",
       "      <td>0.655528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>MLP</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795278</td>\n",
       "      <td>0.74394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.766890</td>\n",
       "      <td>0.665712</td>\n",
       "      <td>0.773168</td>\n",
       "      <td>0.680313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>MLP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.772758</td>\n",
       "      <td>0.67938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.764979</td>\n",
       "      <td>0.663116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>MLP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.774806</td>\n",
       "      <td>0.687703</td>\n",
       "      <td>0.793913</td>\n",
       "      <td>0.737667</td>\n",
       "      <td>0.793776</td>\n",
       "      <td>0.743148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy_1      f1_1  accuracy_51     f1_51  accuracy_88     f1_88  \\\n",
       "0     0.767436  0.666454     0.781766  0.703452     0.795278  0.734284   \n",
       "1     0.760338  0.656822          NaN       NaN          NaN       NaN   \n",
       "2     0.765934  0.664413          NaN       NaN          NaN       NaN   \n",
       "3          NaN       NaN          NaN       NaN          NaN       NaN   \n",
       "4     0.755425  0.650175          NaN       NaN          NaN       NaN   \n",
       "5          NaN       NaN     0.786952  0.733573          NaN       NaN   \n",
       "6     0.755835  0.650729     0.785997  0.751336          NaN       NaN   \n",
       "7     0.760202  0.656637          NaN       NaN          NaN       NaN   \n",
       "8          NaN       NaN          NaN       NaN          NaN       NaN   \n",
       "9     0.756790  0.652020          NaN       NaN          NaN       NaN   \n",
       "10         NaN       NaN          NaN       NaN          NaN       NaN   \n",
       "11    0.755425  0.650175          NaN       NaN          NaN       NaN   \n",
       "12         NaN       NaN          NaN       NaN          NaN       NaN   \n",
       "13    0.757063  0.652389     0.791320  0.737025          NaN       NaN   \n",
       "14    0.763068  0.660522          NaN       NaN          NaN       NaN   \n",
       "15    0.758018  0.653681          NaN       NaN          NaN       NaN   \n",
       "16         NaN       NaN          NaN       NaN          NaN       NaN   \n",
       "17    0.753105  0.647043          NaN       NaN          NaN       NaN   \n",
       "18         NaN       NaN          NaN       NaN          NaN       NaN   \n",
       "19         NaN       NaN          NaN       NaN          NaN       NaN   \n",
       "20         NaN       NaN          NaN       NaN          NaN       NaN   \n",
       "21    0.757745  0.653312          NaN       NaN          NaN       NaN   \n",
       "22    0.759383  0.655528          NaN       NaN          NaN       NaN   \n",
       "23    0.766890  0.665712     0.773168  0.680313          NaN       NaN   \n",
       "24    0.764979  0.663116          NaN       NaN          NaN       NaN   \n",
       "\n",
       "    accuracy_137    f1_137  Seed Model  ... accuracy_94    f1_94  accuracy_50  \\\n",
       "0       0.797598  0.740024     0   MLP  ...         NaN      NaN          NaN   \n",
       "1            NaN       NaN     1   MLP  ...         NaN      NaN          NaN   \n",
       "2            NaN       NaN     2   MLP  ...         NaN      NaN          NaN   \n",
       "3            NaN       NaN     3   MLP  ...         NaN      NaN          NaN   \n",
       "4            NaN       NaN     4   MLP  ...         NaN      NaN          NaN   \n",
       "5            NaN       NaN     5   MLP  ...         NaN      NaN          NaN   \n",
       "6            NaN       NaN     6   MLP  ...         NaN      NaN          NaN   \n",
       "7            NaN       NaN     7   MLP  ...         NaN      NaN          NaN   \n",
       "8            NaN       NaN     8   MLP  ...         NaN      NaN          NaN   \n",
       "9            NaN       NaN     9   MLP  ...         NaN      NaN          NaN   \n",
       "10           NaN       NaN    10   MLP  ...         NaN      NaN          NaN   \n",
       "11           NaN       NaN    11   MLP  ...         NaN      NaN          NaN   \n",
       "12           NaN       NaN    12   MLP  ...         NaN      NaN          NaN   \n",
       "13           NaN       NaN    13   MLP  ...         NaN      NaN          NaN   \n",
       "14           NaN       NaN    14   MLP  ...         NaN      NaN          NaN   \n",
       "15           NaN       NaN    15   MLP  ...         NaN      NaN          NaN   \n",
       "16           NaN       NaN    16   MLP  ...         NaN      NaN          NaN   \n",
       "17           NaN       NaN    17   MLP  ...         NaN      NaN          NaN   \n",
       "18           NaN       NaN    18   MLP  ...         NaN      NaN          NaN   \n",
       "19           NaN       NaN    19   MLP  ...         NaN      NaN          NaN   \n",
       "20           NaN       NaN    20   MLP  ...         NaN      NaN          NaN   \n",
       "21           NaN       NaN    21   MLP  ...         NaN      NaN          NaN   \n",
       "22           NaN       NaN    22   MLP  ...    0.795278  0.74394          NaN   \n",
       "23           NaN       NaN    23   MLP  ...         NaN      NaN     0.772758   \n",
       "24           NaN       NaN    24   MLP  ...         NaN      NaN          NaN   \n",
       "\n",
       "      f1_50  accuracy_96     f1_96  accuracy_227    f1_227  accuracy_281  \\\n",
       "0       NaN          NaN       NaN           NaN       NaN           NaN   \n",
       "1       NaN          NaN       NaN           NaN       NaN           NaN   \n",
       "2       NaN          NaN       NaN           NaN       NaN           NaN   \n",
       "3       NaN          NaN       NaN           NaN       NaN           NaN   \n",
       "4       NaN          NaN       NaN           NaN       NaN           NaN   \n",
       "5       NaN          NaN       NaN           NaN       NaN           NaN   \n",
       "6       NaN          NaN       NaN           NaN       NaN           NaN   \n",
       "7       NaN          NaN       NaN           NaN       NaN           NaN   \n",
       "8       NaN          NaN       NaN           NaN       NaN           NaN   \n",
       "9       NaN          NaN       NaN           NaN       NaN           NaN   \n",
       "10      NaN          NaN       NaN           NaN       NaN           NaN   \n",
       "11      NaN          NaN       NaN           NaN       NaN           NaN   \n",
       "12      NaN          NaN       NaN           NaN       NaN           NaN   \n",
       "13      NaN          NaN       NaN           NaN       NaN           NaN   \n",
       "14      NaN          NaN       NaN           NaN       NaN           NaN   \n",
       "15      NaN          NaN       NaN           NaN       NaN           NaN   \n",
       "16      NaN          NaN       NaN           NaN       NaN           NaN   \n",
       "17      NaN          NaN       NaN           NaN       NaN           NaN   \n",
       "18      NaN          NaN       NaN           NaN       NaN           NaN   \n",
       "19      NaN          NaN       NaN           NaN       NaN           NaN   \n",
       "20      NaN          NaN       NaN           NaN       NaN           NaN   \n",
       "21      NaN          NaN       NaN           NaN       NaN           NaN   \n",
       "22      NaN          NaN       NaN           NaN       NaN           NaN   \n",
       "23  0.67938          NaN       NaN           NaN       NaN           NaN   \n",
       "24      NaN     0.774806  0.687703      0.793913  0.737667      0.793776   \n",
       "\n",
       "      f1_281  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  \n",
       "5        NaN  \n",
       "6        NaN  \n",
       "7        NaN  \n",
       "8        NaN  \n",
       "9        NaN  \n",
       "10       NaN  \n",
       "11       NaN  \n",
       "12       NaN  \n",
       "13       NaN  \n",
       "14       NaN  \n",
       "15       NaN  \n",
       "16       NaN  \n",
       "17       NaN  \n",
       "18       NaN  \n",
       "19       NaN  \n",
       "20       NaN  \n",
       "21       NaN  \n",
       "22       NaN  \n",
       "23       NaN  \n",
       "24  0.743148  \n",
       "\n",
       "[25 rows x 170 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_perfs['Neural-CBP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# pd.DataFrame(data_regrets)\n",
    "# data_regrets\n",
    "\n",
    "samples = []\n",
    "# Iterate over the dictionary to extract data\n",
    "for model, dataset in data_models.items():\n",
    "    for data, approach in dataset.items():\n",
    "        for appr, values in approach.items():\n",
    "            i = 0\n",
    "            for val in values:\n",
    "                # print(i, appr,val)\n",
    "                samples.append([i, model, data, appr, val])\n",
    "                i = i+1\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(samples, columns=['Seed','Model', 'Dataset', 'Approach', 'Value'])\n",
    "df = pd.merge(df, concatenated_df, on=['Model', 'Dataset', 'Approach', 'Seed'])\n",
    "\n",
    "# Calculate mean and standard error for each group\n",
    "# grouped = df.groupby(['Model', 'Dataset', 'Approach'])\n",
    "# mean = grouped['Value'].mean().reset_index()\n",
    "# std_error = grouped['Value'].std() / np.sqrt(grouped['Value'].count())\n",
    "# std_error = std_error.reset_index()\n",
    "# # Merge the mean and standard error into a single DataFrame\n",
    "# result = pd.merge(mean, std_error, on=['Model', 'Dataset', 'Approach'])\n",
    "# result.rename(columns={'Value_x': 'Mean', 'Value_y': 'StdError'}, inplace=True)\n",
    "# result['merge'] = result['Model'] + result['Approach']\n",
    "# result['merge2'] = result['Model'] + result['Dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seed</th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Approach</th>\n",
       "      <th>Value</th>\n",
       "      <th>f1_10</th>\n",
       "      <th>f1_50</th>\n",
       "      <th>f1_100</th>\n",
       "      <th>f1_250</th>\n",
       "      <th>f1_500</th>\n",
       "      <th>f1_750</th>\n",
       "      <th>f1_1000</th>\n",
       "      <th>f1_2500</th>\n",
       "      <th>f1_5000</th>\n",
       "      <th>f1_7500</th>\n",
       "      <th>f1_9000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MLP</td>\n",
       "      <td>MNISTbinary</td>\n",
       "      <td>Neural-CBP</td>\n",
       "      <td>1353.0</td>\n",
       "      <td>0.606952</td>\n",
       "      <td>0.658141</td>\n",
       "      <td>0.687527</td>\n",
       "      <td>0.655565</td>\n",
       "      <td>0.683871</td>\n",
       "      <td>0.842492</td>\n",
       "      <td>0.860063</td>\n",
       "      <td>0.904477</td>\n",
       "      <td>0.940901</td>\n",
       "      <td>0.950569</td>\n",
       "      <td>0.957999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MLP</td>\n",
       "      <td>MNISTbinary</td>\n",
       "      <td>Neural-CBP</td>\n",
       "      <td>1352.0</td>\n",
       "      <td>0.626424</td>\n",
       "      <td>0.697114</td>\n",
       "      <td>0.732544</td>\n",
       "      <td>0.668211</td>\n",
       "      <td>0.848383</td>\n",
       "      <td>0.808356</td>\n",
       "      <td>0.869250</td>\n",
       "      <td>0.808366</td>\n",
       "      <td>0.925002</td>\n",
       "      <td>0.928905</td>\n",
       "      <td>0.928030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>MLP</td>\n",
       "      <td>MNISTbinary</td>\n",
       "      <td>Neural-CBP</td>\n",
       "      <td>1556.0</td>\n",
       "      <td>0.348610</td>\n",
       "      <td>0.711514</td>\n",
       "      <td>0.717050</td>\n",
       "      <td>0.780392</td>\n",
       "      <td>0.581689</td>\n",
       "      <td>0.800759</td>\n",
       "      <td>0.752274</td>\n",
       "      <td>0.845571</td>\n",
       "      <td>0.916238</td>\n",
       "      <td>0.944848</td>\n",
       "      <td>0.956199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>MLP</td>\n",
       "      <td>MNISTbinary</td>\n",
       "      <td>Neural-CBP</td>\n",
       "      <td>1298.0</td>\n",
       "      <td>0.386775</td>\n",
       "      <td>0.702732</td>\n",
       "      <td>0.748480</td>\n",
       "      <td>0.752430</td>\n",
       "      <td>0.852819</td>\n",
       "      <td>0.863739</td>\n",
       "      <td>0.862177</td>\n",
       "      <td>0.894895</td>\n",
       "      <td>0.937969</td>\n",
       "      <td>0.952063</td>\n",
       "      <td>0.956900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>MLP</td>\n",
       "      <td>MNISTbinary</td>\n",
       "      <td>Neural-CBP</td>\n",
       "      <td>1346.0</td>\n",
       "      <td>0.331491</td>\n",
       "      <td>0.685806</td>\n",
       "      <td>0.729398</td>\n",
       "      <td>0.622473</td>\n",
       "      <td>0.711874</td>\n",
       "      <td>0.844268</td>\n",
       "      <td>0.875452</td>\n",
       "      <td>0.878335</td>\n",
       "      <td>0.937975</td>\n",
       "      <td>0.953693</td>\n",
       "      <td>0.958202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>20</td>\n",
       "      <td>MLP</td>\n",
       "      <td>adult</td>\n",
       "      <td>Cesa</td>\n",
       "      <td>2518.0</td>\n",
       "      <td>0.090862</td>\n",
       "      <td>0.090862</td>\n",
       "      <td>0.090862</td>\n",
       "      <td>0.090862</td>\n",
       "      <td>0.090862</td>\n",
       "      <td>0.090862</td>\n",
       "      <td>0.090862</td>\n",
       "      <td>0.090862</td>\n",
       "      <td>0.090862</td>\n",
       "      <td>0.090862</td>\n",
       "      <td>0.090862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>21</td>\n",
       "      <td>MLP</td>\n",
       "      <td>adult</td>\n",
       "      <td>Cesa</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>0.664228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>22</td>\n",
       "      <td>MLP</td>\n",
       "      <td>adult</td>\n",
       "      <td>Cesa</td>\n",
       "      <td>7543.0</td>\n",
       "      <td>0.093335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>23</td>\n",
       "      <td>MLP</td>\n",
       "      <td>adult</td>\n",
       "      <td>Cesa</td>\n",
       "      <td>2335.0</td>\n",
       "      <td>0.651098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>24</td>\n",
       "      <td>MLP</td>\n",
       "      <td>adult</td>\n",
       "      <td>Cesa</td>\n",
       "      <td>2499.0</td>\n",
       "      <td>0.097580</td>\n",
       "      <td>0.097580</td>\n",
       "      <td>0.097580</td>\n",
       "      <td>0.097580</td>\n",
       "      <td>0.097580</td>\n",
       "      <td>0.097580</td>\n",
       "      <td>0.097580</td>\n",
       "      <td>0.097580</td>\n",
       "      <td>0.097580</td>\n",
       "      <td>0.097580</td>\n",
       "      <td>0.097580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>525 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Seed Model      Dataset    Approach   Value     f1_10     f1_50  \\\n",
       "0       0   MLP  MNISTbinary  Neural-CBP  1353.0  0.606952  0.658141   \n",
       "1       1   MLP  MNISTbinary  Neural-CBP  1352.0  0.626424  0.697114   \n",
       "2       2   MLP  MNISTbinary  Neural-CBP  1556.0  0.348610  0.711514   \n",
       "3       3   MLP  MNISTbinary  Neural-CBP  1298.0  0.386775  0.702732   \n",
       "4       4   MLP  MNISTbinary  Neural-CBP  1346.0  0.331491  0.685806   \n",
       "..    ...   ...          ...         ...     ...       ...       ...   \n",
       "520    20   MLP        adult        Cesa  2518.0  0.090862  0.090862   \n",
       "521    21   MLP        adult        Cesa  2400.0  0.664228       NaN   \n",
       "522    22   MLP        adult        Cesa  7543.0  0.093335       NaN   \n",
       "523    23   MLP        adult        Cesa  2335.0  0.651098       NaN   \n",
       "524    24   MLP        adult        Cesa  2499.0  0.097580  0.097580   \n",
       "\n",
       "       f1_100    f1_250    f1_500    f1_750   f1_1000   f1_2500   f1_5000  \\\n",
       "0    0.687527  0.655565  0.683871  0.842492  0.860063  0.904477  0.940901   \n",
       "1    0.732544  0.668211  0.848383  0.808356  0.869250  0.808366  0.925002   \n",
       "2    0.717050  0.780392  0.581689  0.800759  0.752274  0.845571  0.916238   \n",
       "3    0.748480  0.752430  0.852819  0.863739  0.862177  0.894895  0.937969   \n",
       "4    0.729398  0.622473  0.711874  0.844268  0.875452  0.878335  0.937975   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "520  0.090862  0.090862  0.090862  0.090862  0.090862  0.090862  0.090862   \n",
       "521       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "522       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "523       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "524  0.097580  0.097580  0.097580  0.097580  0.097580  0.097580  0.097580   \n",
       "\n",
       "      f1_7500   f1_9000  \n",
       "0    0.950569  0.957999  \n",
       "1    0.928905  0.928030  \n",
       "2    0.944848  0.956199  \n",
       "3    0.952063  0.956900  \n",
       "4    0.953693  0.958202  \n",
       "..        ...       ...  \n",
       "520  0.090862  0.090862  \n",
       "521       NaN       NaN  \n",
       "522       NaN       NaN  \n",
       "523       NaN       NaN  \n",
       "524  0.097580  0.097580  \n",
       "\n",
       "[525 rows x 16 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('experiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>f1_10</th>\n",
       "      <th>f1_50</th>\n",
       "      <th>f1_100</th>\n",
       "      <th>f1_250</th>\n",
       "      <th>f1_500</th>\n",
       "      <th>f1_750</th>\n",
       "      <th>f1_1000</th>\n",
       "      <th>f1_2500</th>\n",
       "      <th>f1_5000</th>\n",
       "      <th>f1_7500</th>\n",
       "      <th>f1_9000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Approach</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"21\" valign=\"top\">MLP</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">MNISTbinary</th>\n",
       "      <th>Cesa</th>\n",
       "      <td>4892.52</td>\n",
       "      <td>0.325144</td>\n",
       "      <td>0.325144</td>\n",
       "      <td>0.325144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IneurAL (official)</th>\n",
       "      <td>3929.48</td>\n",
       "      <td>0.612091</td>\n",
       "      <td>0.752062</td>\n",
       "      <td>0.794428</td>\n",
       "      <td>0.857583</td>\n",
       "      <td>0.884114</td>\n",
       "      <td>0.906983</td>\n",
       "      <td>0.922758</td>\n",
       "      <td>0.943871</td>\n",
       "      <td>0.960015</td>\n",
       "      <td>0.967090</td>\n",
       "      <td>0.969614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IneurAL (tuned)</th>\n",
       "      <td>1726.96</td>\n",
       "      <td>0.456605</td>\n",
       "      <td>0.617890</td>\n",
       "      <td>0.729011</td>\n",
       "      <td>0.811667</td>\n",
       "      <td>0.858388</td>\n",
       "      <td>0.884166</td>\n",
       "      <td>0.902044</td>\n",
       "      <td>0.937170</td>\n",
       "      <td>0.953078</td>\n",
       "      <td>0.959209</td>\n",
       "      <td>0.963119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Margin</th>\n",
       "      <td>3216.72</td>\n",
       "      <td>0.325144</td>\n",
       "      <td>0.325144</td>\n",
       "      <td>0.325144</td>\n",
       "      <td>0.325144</td>\n",
       "      <td>0.325144</td>\n",
       "      <td>0.325144</td>\n",
       "      <td>0.325144</td>\n",
       "      <td>0.325144</td>\n",
       "      <td>0.325144</td>\n",
       "      <td>0.325144</td>\n",
       "      <td>0.325144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural-CBP</th>\n",
       "      <td>1351.92</td>\n",
       "      <td>0.418724</td>\n",
       "      <td>0.633312</td>\n",
       "      <td>0.695250</td>\n",
       "      <td>0.732279</td>\n",
       "      <td>0.783948</td>\n",
       "      <td>0.826354</td>\n",
       "      <td>0.855935</td>\n",
       "      <td>0.887865</td>\n",
       "      <td>0.929552</td>\n",
       "      <td>0.940161</td>\n",
       "      <td>0.949804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neuronal (official)</th>\n",
       "      <td>1721.88</td>\n",
       "      <td>0.488159</td>\n",
       "      <td>0.748138</td>\n",
       "      <td>0.762319</td>\n",
       "      <td>0.804093</td>\n",
       "      <td>0.850893</td>\n",
       "      <td>0.875949</td>\n",
       "      <td>0.895454</td>\n",
       "      <td>0.941863</td>\n",
       "      <td>0.958896</td>\n",
       "      <td>0.964725</td>\n",
       "      <td>0.967169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neuronal (tuned)</th>\n",
       "      <td>1721.44</td>\n",
       "      <td>0.466616</td>\n",
       "      <td>0.660361</td>\n",
       "      <td>0.686202</td>\n",
       "      <td>0.735821</td>\n",
       "      <td>0.819473</td>\n",
       "      <td>0.852157</td>\n",
       "      <td>0.870334</td>\n",
       "      <td>0.915605</td>\n",
       "      <td>0.943974</td>\n",
       "      <td>0.953555</td>\n",
       "      <td>0.957200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">MagicTelescope</th>\n",
       "      <th>Cesa</th>\n",
       "      <td>3451.64</td>\n",
       "      <td>0.390923</td>\n",
       "      <td>0.385641</td>\n",
       "      <td>0.385641</td>\n",
       "      <td>0.389531</td>\n",
       "      <td>0.361979</td>\n",
       "      <td>0.353419</td>\n",
       "      <td>0.364937</td>\n",
       "      <td>0.364937</td>\n",
       "      <td>0.355257</td>\n",
       "      <td>0.343176</td>\n",
       "      <td>0.343176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IneurAL (official)</th>\n",
       "      <td>8999.76</td>\n",
       "      <td>0.550029</td>\n",
       "      <td>0.632660</td>\n",
       "      <td>0.655699</td>\n",
       "      <td>0.684788</td>\n",
       "      <td>0.724059</td>\n",
       "      <td>0.743932</td>\n",
       "      <td>0.750132</td>\n",
       "      <td>0.762013</td>\n",
       "      <td>0.765829</td>\n",
       "      <td>0.768016</td>\n",
       "      <td>0.803735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IneurAL (tuned)</th>\n",
       "      <td>6184.00</td>\n",
       "      <td>0.416895</td>\n",
       "      <td>0.520491</td>\n",
       "      <td>0.588354</td>\n",
       "      <td>0.628474</td>\n",
       "      <td>0.708319</td>\n",
       "      <td>0.752577</td>\n",
       "      <td>0.793863</td>\n",
       "      <td>0.802204</td>\n",
       "      <td>0.803434</td>\n",
       "      <td>0.803700</td>\n",
       "      <td>0.806752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Margin</th>\n",
       "      <td>3445.80</td>\n",
       "      <td>0.356284</td>\n",
       "      <td>0.369053</td>\n",
       "      <td>0.369053</td>\n",
       "      <td>0.369053</td>\n",
       "      <td>0.369053</td>\n",
       "      <td>0.369053</td>\n",
       "      <td>0.369053</td>\n",
       "      <td>0.369053</td>\n",
       "      <td>0.361729</td>\n",
       "      <td>0.371872</td>\n",
       "      <td>0.383661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural-CBP</th>\n",
       "      <td>3362.60</td>\n",
       "      <td>0.505780</td>\n",
       "      <td>0.536101</td>\n",
       "      <td>0.606089</td>\n",
       "      <td>0.649602</td>\n",
       "      <td>0.673629</td>\n",
       "      <td>0.696050</td>\n",
       "      <td>0.712167</td>\n",
       "      <td>0.729095</td>\n",
       "      <td>0.750162</td>\n",
       "      <td>0.769804</td>\n",
       "      <td>0.783379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neuronal (official)</th>\n",
       "      <td>4307.36</td>\n",
       "      <td>0.464284</td>\n",
       "      <td>0.637021</td>\n",
       "      <td>0.635156</td>\n",
       "      <td>0.644367</td>\n",
       "      <td>0.668132</td>\n",
       "      <td>0.685227</td>\n",
       "      <td>0.694182</td>\n",
       "      <td>0.711076</td>\n",
       "      <td>0.747621</td>\n",
       "      <td>0.784382</td>\n",
       "      <td>0.794908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neuronal (tuned)</th>\n",
       "      <td>4296.48</td>\n",
       "      <td>0.400628</td>\n",
       "      <td>0.572652</td>\n",
       "      <td>0.619743</td>\n",
       "      <td>0.689549</td>\n",
       "      <td>0.697437</td>\n",
       "      <td>0.703638</td>\n",
       "      <td>0.702443</td>\n",
       "      <td>0.708795</td>\n",
       "      <td>0.714171</td>\n",
       "      <td>0.717597</td>\n",
       "      <td>0.720259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">adult</th>\n",
       "      <th>Cesa</th>\n",
       "      <td>2640.40</td>\n",
       "      <td>0.431680</td>\n",
       "      <td>0.389566</td>\n",
       "      <td>0.339744</td>\n",
       "      <td>0.295502</td>\n",
       "      <td>0.295502</td>\n",
       "      <td>0.295502</td>\n",
       "      <td>0.295502</td>\n",
       "      <td>0.295502</td>\n",
       "      <td>0.295502</td>\n",
       "      <td>0.295502</td>\n",
       "      <td>0.295502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IneurAL (official)</th>\n",
       "      <td>8974.72</td>\n",
       "      <td>0.576245</td>\n",
       "      <td>0.641535</td>\n",
       "      <td>0.602028</td>\n",
       "      <td>0.673637</td>\n",
       "      <td>0.714411</td>\n",
       "      <td>0.741234</td>\n",
       "      <td>0.748889</td>\n",
       "      <td>0.695185</td>\n",
       "      <td>0.759210</td>\n",
       "      <td>0.773508</td>\n",
       "      <td>0.775071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IneurAL (tuned)</th>\n",
       "      <td>4904.08</td>\n",
       "      <td>0.498365</td>\n",
       "      <td>0.534224</td>\n",
       "      <td>0.662131</td>\n",
       "      <td>0.724369</td>\n",
       "      <td>0.692193</td>\n",
       "      <td>0.735677</td>\n",
       "      <td>0.746892</td>\n",
       "      <td>0.754601</td>\n",
       "      <td>0.743929</td>\n",
       "      <td>0.751921</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Margin</th>\n",
       "      <td>2331.44</td>\n",
       "      <td>0.408914</td>\n",
       "      <td>0.532065</td>\n",
       "      <td>0.587180</td>\n",
       "      <td>0.563870</td>\n",
       "      <td>0.563870</td>\n",
       "      <td>0.544577</td>\n",
       "      <td>0.467029</td>\n",
       "      <td>0.653589</td>\n",
       "      <td>0.653589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural-CBP</th>\n",
       "      <td>2642.76</td>\n",
       "      <td>0.657573</td>\n",
       "      <td>0.621437</td>\n",
       "      <td>0.604684</td>\n",
       "      <td>0.690898</td>\n",
       "      <td>0.694309</td>\n",
       "      <td>0.735240</td>\n",
       "      <td>0.738204</td>\n",
       "      <td>0.738071</td>\n",
       "      <td>0.664142</td>\n",
       "      <td>0.720530</td>\n",
       "      <td>0.733573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neuronal (official)</th>\n",
       "      <td>4730.92</td>\n",
       "      <td>0.612930</td>\n",
       "      <td>0.665917</td>\n",
       "      <td>0.670008</td>\n",
       "      <td>0.674241</td>\n",
       "      <td>0.681350</td>\n",
       "      <td>0.690242</td>\n",
       "      <td>0.697182</td>\n",
       "      <td>0.710602</td>\n",
       "      <td>0.730164</td>\n",
       "      <td>0.740135</td>\n",
       "      <td>0.743024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neuronal (tuned)</th>\n",
       "      <td>3717.32</td>\n",
       "      <td>0.501466</td>\n",
       "      <td>0.666578</td>\n",
       "      <td>0.676928</td>\n",
       "      <td>0.683907</td>\n",
       "      <td>0.573205</td>\n",
       "      <td>0.699427</td>\n",
       "      <td>0.704271</td>\n",
       "      <td>0.711024</td>\n",
       "      <td>0.710119</td>\n",
       "      <td>0.733500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Value     f1_10     f1_50  \\\n",
       "                                             mean      mean      mean   \n",
       "Model Dataset        Approach                                           \n",
       "MLP   MNISTbinary    Cesa                 4892.52  0.325144  0.325144   \n",
       "                     IneurAL (official)   3929.48  0.612091  0.752062   \n",
       "                     IneurAL (tuned)      1726.96  0.456605  0.617890   \n",
       "                     Margin               3216.72  0.325144  0.325144   \n",
       "                     Neural-CBP           1351.92  0.418724  0.633312   \n",
       "                     Neuronal (official)  1721.88  0.488159  0.748138   \n",
       "                     Neuronal (tuned)     1721.44  0.466616  0.660361   \n",
       "      MagicTelescope Cesa                 3451.64  0.390923  0.385641   \n",
       "                     IneurAL (official)   8999.76  0.550029  0.632660   \n",
       "                     IneurAL (tuned)      6184.00  0.416895  0.520491   \n",
       "                     Margin               3445.80  0.356284  0.369053   \n",
       "                     Neural-CBP           3362.60  0.505780  0.536101   \n",
       "                     Neuronal (official)  4307.36  0.464284  0.637021   \n",
       "                     Neuronal (tuned)     4296.48  0.400628  0.572652   \n",
       "      adult          Cesa                 2640.40  0.431680  0.389566   \n",
       "                     IneurAL (official)   8974.72  0.576245  0.641535   \n",
       "                     IneurAL (tuned)      4904.08  0.498365  0.534224   \n",
       "                     Margin               2331.44  0.408914  0.532065   \n",
       "                     Neural-CBP           2642.76  0.657573  0.621437   \n",
       "                     Neuronal (official)  4730.92  0.612930  0.665917   \n",
       "                     Neuronal (tuned)     3717.32  0.501466  0.666578   \n",
       "\n",
       "                                            f1_100    f1_250    f1_500  \\\n",
       "                                              mean      mean      mean   \n",
       "Model Dataset        Approach                                            \n",
       "MLP   MNISTbinary    Cesa                 0.325144       NaN       NaN   \n",
       "                     IneurAL (official)   0.794428  0.857583  0.884114   \n",
       "                     IneurAL (tuned)      0.729011  0.811667  0.858388   \n",
       "                     Margin               0.325144  0.325144  0.325144   \n",
       "                     Neural-CBP           0.695250  0.732279  0.783948   \n",
       "                     Neuronal (official)  0.762319  0.804093  0.850893   \n",
       "                     Neuronal (tuned)     0.686202  0.735821  0.819473   \n",
       "      MagicTelescope Cesa                 0.385641  0.389531  0.361979   \n",
       "                     IneurAL (official)   0.655699  0.684788  0.724059   \n",
       "                     IneurAL (tuned)      0.588354  0.628474  0.708319   \n",
       "                     Margin               0.369053  0.369053  0.369053   \n",
       "                     Neural-CBP           0.606089  0.649602  0.673629   \n",
       "                     Neuronal (official)  0.635156  0.644367  0.668132   \n",
       "                     Neuronal (tuned)     0.619743  0.689549  0.697437   \n",
       "      adult          Cesa                 0.339744  0.295502  0.295502   \n",
       "                     IneurAL (official)   0.602028  0.673637  0.714411   \n",
       "                     IneurAL (tuned)      0.662131  0.724369  0.692193   \n",
       "                     Margin               0.587180  0.563870  0.563870   \n",
       "                     Neural-CBP           0.604684  0.690898  0.694309   \n",
       "                     Neuronal (official)  0.670008  0.674241  0.681350   \n",
       "                     Neuronal (tuned)     0.676928  0.683907  0.573205   \n",
       "\n",
       "                                            f1_750   f1_1000   f1_2500  \\\n",
       "                                              mean      mean      mean   \n",
       "Model Dataset        Approach                                            \n",
       "MLP   MNISTbinary    Cesa                      NaN       NaN       NaN   \n",
       "                     IneurAL (official)   0.906983  0.922758  0.943871   \n",
       "                     IneurAL (tuned)      0.884166  0.902044  0.937170   \n",
       "                     Margin               0.325144  0.325144  0.325144   \n",
       "                     Neural-CBP           0.826354  0.855935  0.887865   \n",
       "                     Neuronal (official)  0.875949  0.895454  0.941863   \n",
       "                     Neuronal (tuned)     0.852157  0.870334  0.915605   \n",
       "      MagicTelescope Cesa                 0.353419  0.364937  0.364937   \n",
       "                     IneurAL (official)   0.743932  0.750132  0.762013   \n",
       "                     IneurAL (tuned)      0.752577  0.793863  0.802204   \n",
       "                     Margin               0.369053  0.369053  0.369053   \n",
       "                     Neural-CBP           0.696050  0.712167  0.729095   \n",
       "                     Neuronal (official)  0.685227  0.694182  0.711076   \n",
       "                     Neuronal (tuned)     0.703638  0.702443  0.708795   \n",
       "      adult          Cesa                 0.295502  0.295502  0.295502   \n",
       "                     IneurAL (official)   0.741234  0.748889  0.695185   \n",
       "                     IneurAL (tuned)      0.735677  0.746892  0.754601   \n",
       "                     Margin               0.544577  0.467029  0.653589   \n",
       "                     Neural-CBP           0.735240  0.738204  0.738071   \n",
       "                     Neuronal (official)  0.690242  0.697182  0.710602   \n",
       "                     Neuronal (tuned)     0.699427  0.704271  0.711024   \n",
       "\n",
       "                                           f1_5000   f1_7500   f1_9000  \n",
       "                                              mean      mean      mean  \n",
       "Model Dataset        Approach                                           \n",
       "MLP   MNISTbinary    Cesa                      NaN       NaN       NaN  \n",
       "                     IneurAL (official)   0.960015  0.967090  0.969614  \n",
       "                     IneurAL (tuned)      0.953078  0.959209  0.963119  \n",
       "                     Margin               0.325144  0.325144  0.325144  \n",
       "                     Neural-CBP           0.929552  0.940161  0.949804  \n",
       "                     Neuronal (official)  0.958896  0.964725  0.967169  \n",
       "                     Neuronal (tuned)     0.943974  0.953555  0.957200  \n",
       "      MagicTelescope Cesa                 0.355257  0.343176  0.343176  \n",
       "                     IneurAL (official)   0.765829  0.768016  0.803735  \n",
       "                     IneurAL (tuned)      0.803434  0.803700  0.806752  \n",
       "                     Margin               0.361729  0.371872  0.383661  \n",
       "                     Neural-CBP           0.750162  0.769804  0.783379  \n",
       "                     Neuronal (official)  0.747621  0.784382  0.794908  \n",
       "                     Neuronal (tuned)     0.714171  0.717597  0.720259  \n",
       "      adult          Cesa                 0.295502  0.295502  0.295502  \n",
       "                     IneurAL (official)   0.759210  0.773508  0.775071  \n",
       "                     IneurAL (tuned)      0.743929  0.751921       NaN  \n",
       "                     Margin               0.653589       NaN       NaN  \n",
       "                     Neural-CBP           0.664142  0.720530  0.733573  \n",
       "                     Neuronal (official)  0.730164  0.740135  0.743024  \n",
       "                     Neuronal (tuned)     0.710119  0.733500       NaN  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataframe from the provided file\n",
    "# df = pd.read_csv('/mnt/data/experiment.csv')\n",
    "\n",
    "# Columns to exclude from the aggregation\n",
    "exclude_columns = ['Seed', 'Model', 'Dataset', 'Approach']\n",
    "\n",
    "# Selecting the columns for which to calculate mean and std\n",
    "agg_columns = [col for col in df.columns if col not in exclude_columns]\n",
    "\n",
    "# Grouping by 'Model', 'Dataset', 'Approach' and calculating mean and std\n",
    "grouped_df = df.groupby(['Model', 'Dataset', 'Approach'])[agg_columns].agg(['mean']) #, 'std'\n",
    "\n",
    "grouped_df#.head()  # Display the first few rows of the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('experiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MLPMNIST binary' 'MLPMagicTelescope' 'MLPadult']\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "error_y": {
          "array": [],
          "thickness": 1,
          "type": "data",
          "visible": true
         },
         "marker": {
          "color": "#AB63FA",
          "pattern": {
           "fgcolor": "black",
           "shape": "x"
          }
         },
         "name": "Neural-CBP",
         "type": "bar",
         "x": [],
         "y": []
        },
        {
         "error_y": {
          "array": [],
          "thickness": 1,
          "type": "data",
          "visible": true
         },
         "marker": {
          "color": "#FFA15A"
         },
         "name": "Neuronal (official)",
         "showlegend": true,
         "type": "bar",
         "x": [],
         "y": []
        },
        {
         "error_y": {
          "array": [],
          "thickness": 1,
          "type": "data",
          "visible": true
         },
         "marker": {
          "color": "#19D3F3"
         },
         "name": "Neuronal (tuned)",
         "showlegend": true,
         "type": "bar",
         "x": [],
         "y": []
        },
        {
         "error_y": {
          "array": [
           24.017725690476933,
           249.5383412544827,
           308.79584337628876
          ],
          "thickness": 1,
          "type": "data",
          "visible": true
         },
         "marker": {
          "color": "#AB63FA",
          "pattern": {
           "fgcolor": "black",
           "shape": "x"
          }
         },
         "name": "Neural-CBP",
         "type": "bar",
         "x": [
          "MLPMNIST binary",
          "MLPMagicTelescope",
          "MLPadult"
         ],
         "y": [
          1343.4166666666667,
          3437.0833333333335,
          2817.0833333333335
         ]
        },
        {
         "error_y": {
          "array": [
           9.871823466347267,
           176.91410733401753,
           472.1882568685046
          ],
          "thickness": 1,
          "type": "data",
          "visible": true
         },
         "marker": {
          "color": "#FFA15A"
         },
         "name": "Neuronal (official)",
         "showlegend": true,
         "type": "bar",
         "x": [
          "MLPMNIST binary",
          "MLPMagicTelescope",
          "MLPadult"
         ],
         "y": [
          1721,
          4204.541666666667,
          4431.208333333333
         ]
        },
        {
         "error_y": {
          "array": [
           214.88886841790466,
           294.3611048855546,
           299.3976973938012
          ],
          "thickness": 1,
          "type": "data",
          "visible": true
         },
         "marker": {
          "color": "#19D3F3"
         },
         "name": "Neuronal (tuned)",
         "showlegend": true,
         "type": "bar",
         "x": [
          "MLPMNIST binary",
          "MLPMagicTelescope",
          "MLPadult"
         ],
         "y": [
          1736.875,
          4491.541666666667,
          2849.375
         ]
        },
        {
         "error_y": {
          "array": [
           46.258057628173276,
           42.71996218493316,
           153.44263491658677
          ],
          "thickness": 1,
          "type": "data",
          "visible": true
         },
         "marker": {
          "color": "#FF6692"
         },
         "name": "IneurAL (official)",
         "showlegend": true,
         "type": "bar",
         "x": [
          "MLPMNIST binary",
          "MLPMagicTelescope",
          "MLPadult"
         ],
         "y": [
          3924.4583333333335,
          9097.666666666666,
          9386.25
         ]
        },
        {
         "error_y": {
          "array": [
           145.78887003335979,
           154.8276264139129,
           458.1557184671283
          ],
          "thickness": 1,
          "type": "data",
          "visible": true
         },
         "marker": {
          "color": "#B6E880"
         },
         "name": "IneurAL (tuned)",
         "showlegend": true,
         "type": "bar",
         "x": [
          "MLPMNIST binary",
          "MLPMagicTelescope",
          "MLPadult"
         ],
         "y": [
          1737.4166666666667,
          5767.083333333333,
          4410.375
         ]
        },
        {
         "error_y": {
          "array": [
           103.55124543801143,
           233.9006483210856,
           215.15245251464754
          ],
          "thickness": 1,
          "type": "data",
          "visible": true
         },
         "marker": {
          "color": "#FF97FF"
         },
         "name": "Cesa",
         "showlegend": true,
         "type": "bar",
         "x": [
          "MLPMNIST binary",
          "MLPMagicTelescope",
          "MLPadult"
         ],
         "y": [
          4765.041666666667,
          3529.3333333333335,
          2717.2916666666665
         ]
        },
        {
         "error_y": {
          "array": [
           298.7673497428107,
           249.50310219964473,
           304.18600246264276
          ],
          "thickness": 1,
          "type": "data",
          "visible": true
         },
         "marker": {
          "color": "#FECB52"
         },
         "name": "Margin",
         "showlegend": true,
         "type": "bar",
         "x": [
          "MLPMNIST binary",
          "MLPMagicTelescope",
          "MLPadult"
         ],
         "y": [
          3264.9583333333335,
          4006.75,
          2784.75
         ]
        }
       ],
       "layout": {
        "barmode": "group",
        "height": 220,
        "legend": {
         "font": {
          "size": 13
         },
         "orientation": "h",
         "x": 0.5,
         "xanchor": "center",
         "y": -0.3,
         "yanchor": "bottom"
        },
        "margin": {
         "b": 20,
         "l": 20,
         "r": 1,
         "t": 25
        },
        "paper_bgcolor": "white",
        "plot_bgcolor": "white",
        "shapes": [
         {
          "line": {
           "color": "black",
           "dash": "dot",
           "width": 2
          },
          "type": "line",
          "x0": 0.5,
          "x1": 0.5,
          "xref": "x",
          "y0": 0,
          "y1": 1,
          "yref": "y domain"
         },
         {
          "line": {
           "color": "black",
           "dash": "dot",
           "width": 2
          },
          "type": "line",
          "x0": 1.5,
          "x1": 1.5,
          "xref": "x",
          "y0": 0,
          "y1": 1,
          "yref": "y domain"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 1000,
        "xaxis": {
         "tickfont": {
          "size": 11
         },
         "tickmode": "array",
         "ticktext": [
          "MNIST binary",
          "MagicTelescope",
          "adult"
         ],
         "tickvals": [
          "MLPMNIST binary",
          "MLPMagicTelescope",
          "MLPadult"
         ]
        },
        "yaxis": {
         "gridcolor": "lightgrey",
         "tickfont": {
          "size": 13
         },
         "title": {
          "font": {
           "size": 13
          },
          "standoff": 10,
          "text": "Final regret ± standard dev."
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "# Assuming df is your DataFrame and it has columns 'Dataset', 'Value', 'Model'\n",
    "\n",
    "w = 0.1\n",
    "def remove_substrings(s, substrings):\n",
    "    for substring in substrings:\n",
    "        s = s.replace(substring, '')\n",
    "    return s\n",
    "\n",
    "\n",
    "# approaches = result['merge'].unique()\n",
    "approaches = np.array(['LeNetNeural-CBP', 'LeNetNeuronal (official)', 'LeNetNeuronal (tuned)',\n",
    "                        'MLPNeural-CBP', 'MLPNeuronal (official)','MLPNeuronal (tuned)', 'MLPIneurAL (official)', \n",
    "                        'MLPIneurAL (tuned)',  'MLPCesa', 'MLPMargin' ], dtype=object) \n",
    "approaches_names = [ remove_substrings(model, ['LeNet', 'MLP']) for model in approaches ]\n",
    "default_colors = px.colors.qualitative.Plotly\n",
    "model_colors = {model_n:col for model_n,col in zip(approaches_names,default_colors) }\n",
    "\n",
    "\n",
    "# Create an empty figure\n",
    "fig = go.Figure()\n",
    "\n",
    "\n",
    "views = []\n",
    "for appr, appr_name in zip(approaches,approaches_names):\n",
    "\n",
    "    subset = result[result['merge'] == appr]\n",
    "    # dec = False\n",
    "    # if appr_name not in views:\n",
    "    #     dec = True\n",
    "    #     views.append(appr_name)\n",
    "    \n",
    "\n",
    "    if 'CBP' in appr_name:\n",
    "        fig.add_trace(go.Bar(\n",
    "            x=subset['merge2'],\n",
    "            y=subset['Mean'],\n",
    "            name=appr_name,\n",
    "            error_y=dict(type='data', array=subset['StdError'], visible=True,thickness=1 ),\n",
    "            marker_color=model_colors[appr_name],marker_pattern_shape='x',marker_pattern_fgcolor='black', \n",
    "            # showlegend = dec,\n",
    "            # width=w\n",
    "            ))\n",
    "    else: \n",
    "        fig.add_trace(go.Bar(\n",
    "            x=subset['merge2'],\n",
    "            y=subset['Mean'],\n",
    "            name=appr_name,\n",
    "            error_y=dict(type='data', array=subset['StdError'], visible=True,thickness=1 ),\n",
    "            marker_color=model_colors[appr_name], \n",
    "            # showlegend = dec,\n",
    "            # width=w\n",
    "            ))\n",
    "\n",
    "\n",
    "# Add vertical black lines between data groups\n",
    "\n",
    "datasets = result['merge2'].unique()\n",
    "print(datasets)\n",
    "for i, dataset in enumerate(datasets[:-1]):\n",
    "    if i == 2:\n",
    "        fig.add_vline(x=i + 0.5, line_width=2, line_color=\"black\")\n",
    "    else:\n",
    "        fig.add_vline(x=i + 0.5, line_width=2, line_color=\"black\",  line_dash=\"dot\")\n",
    "\n",
    "\n",
    "siz = 13\n",
    "\n",
    "# fig.add_shape(\n",
    "#     type=\"line\", xref=\"paper\", yref=\"paper\",\n",
    "#     x0=0.31,\n",
    "#     y0=1.01,\n",
    "#     x1=0.99,\n",
    "#     y1=1.01,\n",
    "#     line_width=2,\n",
    "#     label=dict(text=\"MLP\", font=dict(size=siz+2)),\n",
    "# )\n",
    "\n",
    "\n",
    "# fig.add_shape(\n",
    "#     type=\"line\", xref=\"paper\", yref=\"paper\",\n",
    "#     x0=0.31,\n",
    "#     y0=1.0125,\n",
    "#     x1=0.31,\n",
    "#     y1=0.95,\n",
    "#     line_width=2,\n",
    "# )\n",
    "\n",
    "\n",
    "# fig.add_shape(\n",
    "#     type=\"line\", xref=\"paper\", yref=\"paper\",\n",
    "#     x0=0.99,\n",
    "#     y0=1.0125,\n",
    "#     x1=0.99,\n",
    "#     y1=0.95,\n",
    "#     line_width=2,\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# fig.add_shape(\n",
    "#     type=\"line\", xref=\"paper\", yref=\"paper\",\n",
    "#     x0=0.01,\n",
    "#     y0=1.01,\n",
    "#     x1=0.29,\n",
    "#     y1=1.01,\n",
    "#     line_width=2,\n",
    "#     label=dict(text=\"LeNet\", font=dict(size=siz+2)),\n",
    "# )\n",
    "\n",
    "\n",
    "# fig.add_shape(\n",
    "#     type=\"line\", xref=\"paper\", yref=\"paper\",\n",
    "#     x0=0.01,\n",
    "#     y0=1.0125,\n",
    "#     x1=0.01,\n",
    "#     y1=0.95,\n",
    "#     line_width=2,\n",
    "# )\n",
    "\n",
    "# fig.add_shape(\n",
    "#     type=\"line\", xref=\"paper\", yref=\"paper\",\n",
    "#     x0=0.29,\n",
    "#     y0=1.0125,\n",
    "#     x1=0.29,\n",
    "#     y1=0.95,\n",
    "#     line_width=2,\n",
    "# )\n",
    "\n",
    "# fig.update_traces(width=0.05)\n",
    "\n",
    "# fig.update_traces(\n",
    "#     marker_pattern_shape='/',  # This sets a grid-like pattern. Use '+' for a cross pattern.\n",
    "#     marker_pattern_fgcolor='black',  # Foreground color of the pattern\n",
    "#     marker_pattern_bgcolor='rgba(0,0,0,0)'  # Transparent background color for the pattern\n",
    "# )\n",
    "\n",
    "fig.update_layout(\n",
    "    width=1000,\n",
    "    height=220,\n",
    "    plot_bgcolor='white',  # Sets the plot background color\n",
    "    paper_bgcolor='white',  # Sets the overall figure background color\n",
    "    barmode='group',\n",
    "    margin=dict(l=20, r=1, t=25, b=20),  # Small margins\n",
    "    xaxis=dict(\n",
    "        tickmode='array',\n",
    "        tickvals=result['merge2'].unique(),\n",
    "        ticktext = [ remove_substrings(model, ['LeNet', 'MLP']) for model in result['merge2'].unique() ],\n",
    "        tickfont=dict(size=siz-2)  # Increase X-axis tick font size\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        gridcolor='lightgrey',\n",
    "        title=\"Final regret ± standard dev.\",\n",
    "        title_standoff=10,\n",
    "        title_font=dict(size=siz),\n",
    "        tickfont=dict(size=siz)  # Increase Y-axis tick font size\n",
    "    ),\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=-0.3,  # Adjust this value to position the legend\n",
    "        xanchor=\"center\",\n",
    "        x=0.5,\n",
    "        font=dict(size=siz)  # Increase legend font size\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "# fig.write_image(\"./results_MLP.pdf\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
